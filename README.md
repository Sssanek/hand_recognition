# **Аннотация**
В данной МКР решается задача захвата движений кисти руки при помощи алгоритмов компьютерного зрения. Целью работы является имплементация программного кода приложения для компьютера с цифровой камерой, который обеспечивает передачу картинки и осуществляет распознавание жестов руки, выводит скелетную модель её ключевых точек и имеет протокол записи относительного положения кисти для дальнейшего хранения и обработки. В результате работы было реализовано приложение для анализа и сбора данных с камеры, а также алгоритмы обучения нейросетей лежащих в основе приложения для распознавания новых жестов. Полученный результат может быть использован для взаимодействия с дополненной реальностью, а также для дистанционного управления различными устройствами. Созданную программу возможно усовершенствовать на предмет качества работы модели и количества распознаваемых жестов.

In this MCR, the problem of capturing the movements of the hand is solved using computer vision algorithms. The aim of the work is to implement the program code of an application for a computer with a digital camera, which provides image transmission and hand gesture recognition, displays a skeletal model of its key points and has a protocol for recording the relative position of the hand for further storage and processing. As a result of the work, an application was implemented for analyzing and collecting data from the camera, as well as learning algorithms for neural networks underlying the application for recognizing new gestures. The result obtained can be used to interact with augmented reality, as well as to remotely control various devices. The created program can be improved in terms of the quality of the model and the number of recognized gestures.
# Оглавление
[Аннотация	2](#_Toc104497934)

[Введение	4](#_Toc104497935)

[История развития искусственного интеллекта	7](#_Toc104497936)

[Основная концепция нейронных сетей	8](#_Toc104497937)

[Функционал ошибки	11](#_Toc104497938)

[Функции активации	13](#_Toc104497939)

[Сверточные нейронные сети	15](#_Toc104497940)

[Свертки	15](#_Toc104497941)

[Предобученные нейросети	17](#_Toc104497942)

[Фреймворк MediaPipe	18](#_Toc104497943)

[Детектор ладони	18](#_Toc104497944)

[Модель распознавания точек руки	19](#_Toc104497945)

[Классификаторы жестов и движений	22](#_Toc104497946)

[Нормализация данных	22](#_Toc104497947)

[Оптимизаторы	23](#_Toc104497948)

[Переобучение	25](#_Toc104497949)

[Предсказание вероятностей	25](#_Toc104497950)

[Архитектура	26](#_Toc104497951)

[Реализация функционала приложения	28](#_Toc104497952)

[Заключение	29](#_Toc104497953)

[Список использованной литературы	30](#_Toc104497954)

[Приложения	31](#_Toc104497955)



# **Введение**
Компьютерное зрение – это одно из основных направлений в области искусственного интеллекта и связанные с ним подходы для получения, обработки и анализа изображений реальных объектов с целью решения прикладных задач. Распознавание образов является областью компьютерного зрения, которая использует различные методы для получения информации из данных, предоставленных в видео или фото формате.  В данной работе реализуется приложение для распознавания жестов кисти руки при помощи компьютера и цифровой камеры. Ниже рассматриваются различные подходы для распознавания ключевых точек кисти и жестов.

В компьютерном зрении широко применяются нейронные сети, способные показывать достаточно хорошие результаты при решении задач и выявлять зависимости. Концепция нейронных сетей была сформулирована на основе человеческого мозга и нейронов в нем. Получив математическое представление нейронов, появилась возможность выстраивать из них сети и посредством обучения формировать связи.

Для обработки изображений используют 2 основных вида нейронных сетей, классифицируемых по способу восприятия информации: CNN (англ. Convolutional Neural Network – сверточная нейронная сеть) и NN (англ. Neural Network – полносвязная нейронная сеть). Главное отличие в том, что CNN посредством сверток получает информацию и выявляет закономерности о взаимном расположении пикселей в изображении. В то время как NN воспринимает изображение как вектор чисел.

Обучение нейронных сетей со сложной архитектурой на большом массиве данных может занять большое количество времени даже при наличии больших вычислительных мощностей. Определенные ресурсы уходят и на предобработку данных для обучения, которую в компьютерном зрении зачастую делают вручную. Тогда появилось понятие предобученных моделей, которые можно использовать без предварительной настройки или дообучить под конкретную задачу. Таким образом, предобученные нейронные сети экономят много ресурсов и времени.

В данной курсовой работе будет изучен и применен фреймворк Mediapipe от компании Google, выделяющий в пространстве ладонь и ключевые точки на ней. Эти ключевые точки будут использоваться для обучения полносвязной нейронной сети и предсказания жеста кисти руки.

Полносвязная сеть, имплементированная самостоятельно, будет принимать координаты ключевых точек кисти и на их основе выдавать вероятности принадлежности к классам, которыми в данной задаче будут являться названия жестов.

Распознавание жестов рук является неотъемлемой частью для создания дополненной реальности, а также позволит управлять периферийными устройствами при помощи одной лишь камеры, что будет являться бесконтактным интерфейсом взаимодействия с аппаратной частью системы. Таким образом, реализация распознавания знаков и жестов кистей рук позволит вывести взаимодействие оператора (пользователя) и системы на совершенно иной уровень.

Следовательно, выбранная тема курсовой работы является актуальной и современной.

Целью настоящей работы является создание приложения для компьютера, реализующее распознавание пальцев и жестов кисти руки, а также имеющее протокол сбора данных для обработки и анализа.

Для достижения поставленной цели необходимо выполнить следующие задачи:

1. Изучение концепции и основных понятий искусственного интеллекта и нейронных сетей
1. Изучение сверточных нейронных сетей и подбор предобученной модели для поиска ключевых точек
1. Изучение архитектуры выбранной модели
1. Написание модуля, использующего выбранную модель, реализующего протокол получения относительных координат ключевых точек
1. Построение полносвязных нейронных сетей и алгоритма их обучения на собранных данных
1. Реализация окончательной версии ПО, использующего имплементированные ранее сети
# **История развития искусственного интеллекта**
Искусственный интеллект можно рассматривать как некоторые фундаментальные в научном направлении методы, ставящие целью понимание природы интеллекта. Реализация этих методов подразумевает понимание природы человека, ведь создание машины, которая анализирует и думает, как человек, позволит детальнее разобраться в сущности человека. С одной стороны — это область фундаментальных исследований, которые носят отчасти философский характер. С другой стороны – это множество прикладных задач для выполнения работы разной специфики, начиная от рекомендательных систем и заканчивая генерацией изображений по тексту. В итоге искусственный интеллект сводится к набору технологий для решения нестандартных задач, которые невозможно решить без человеческого интеллекта и анализа, например, машинный перевод или распознавание лиц и рук.

Для построения искусственного интеллекта выделяют два основных подхода. Первый подход заключается в исследовании, а именно моделировании, поведения человека по мере решения тех или иных задач. Второй подход основывается на структуре мозга человека, состоящей из сложной системы нейронов и связей между ними, которая позволяет формулировать сложные закономерности.

Идеи создания сознательных машин возникали еще во времена Древней Греции. Например, французский ученый Паскаль в 17 столетии изобрел первую цифровую вычислительную машину – механизм, способный заменить человеческий труд. Возможность разрабатывать программы, выполняющие сложные интеллектуальные задачи, появилась только в прошлом веке, после появления современных компьютеров, способных строить и решать сложные математические модели. В то же время ученые имели уже достаточно представлений, как устроен мозг и начали проводиться исследования подходов. В 1956 году появилось понятие искусственного интеллекта, как объекта исследования. Началом развития привычных нейронных сетей, используемых сейчас, можно считать 1958 год, когда Фрэнк Розенблатт предложил Перцептрон (лат. Perception – восприятие) – логическую модель восприятия информации мозгом. Именно Перцептрон и ляжет в основу многослойных нейронных сетей, описанных ниже.
# **Основная концепция нейронных сетей**
Нейронные сети работают по принципу мозга человека, имеют ту же структуру и объекты в основе. Гиппокамп (Рисунок 1) – это часть мозга, связанная с памятью о конкретных событиях (эпизодической памятью). Зубчатые Фазцы – это одна из частей Гиппокампа, которая состоит из нейронов и их связей. Таким образом, Зубчатые Фазцы являются нейронной сетью, которую Розенблатт интерпретировал в виде математической модели.

![](https://user-images.githubusercontent.com/77668803/174447591-0636aa36-5af1-45ba-9947-e05a6a5412d3.png)
*Рисунок 1 - Гиппокамп*

Реальный состоит из 3 основных частей (Рисунок 2): дендритного дерева, которое крепится ко второй важной в нейроне части – ядру. От ядра уходит аксон, отросток, при помощи которого нейрон посылает свои сигналы, в то время как при помощи дендритного дерева эти сигналы принимаются. Нейроны активируются посредством впрыскивания специального вещества в синаптическую щель.

![](https://user-images.githubusercontent.com/77668803/174447983-ffe4d116-01b5-4316-a7b2-6e1fcc0570c8.png)

*Рисунок 2- строение реального нейрона*

- Взвешенное суммарное воздействие на нейрон определяет его активность.
- Воздействия могут быть активирующими и тормозными, что соответствует положительным весам и отрицательным весам в математической модели.

aj=j=1Nwijxj

yi=Фai=Ф(j=1Nwijxj- ϑi)

На рисунке (Рисунок 3) изображено дендритное дерево, от которого вниз отходит аксон. Из этого можно сформулировать простейшую математическую модель, также изображенную на рисунке. x1, x2, x3, x4, x5 – концентрация тех веществ, которые активируют нейрон, тогда обозначим концентрацию рецепторов в синаптической щели (воспринимающих вещество для активации), как w1, w2, w3, w4, w5. Это значит, что при перемножении этих коэффициентов мы можем получить оценку влияния, которую данный вход вносит в активацию нейрона. После сложения всех этих воздействий появляется возможность сравнить эту сумму с пороговой величиной активации нейрона.

![](https://user-images.githubusercontent.com/77668803/174447673-2dd5f8d2-c5cf-4300-ac66-86eb8d3bd100.png)

*Рисунок 3- математическая модель дендритного дерева*

Введем понятия для дальнейшего использования:

- Слой – структурная единица нейронной сети, которая как правило включает в себя некоторое линейное преобразование, а также функцию активацию.
  - Линейное преобразование: f(x) = wx + b
  - Нелинейное преобразование: f(x) = σ(x)
  - Входной слой (input layer) и выходной слой (output layer)
- Функция активации – функции, которые применяются к выходным значениям с линейных преобразований.
- Нейросеть учится на примерах правильных ответов – обучающая выборка.
- Обучение нейронной сети происходит за счет изменения весов.
- Для проверки того, насколько хорошо прошло обучение, используются примеры, которые не были использованы при обучении – тестовая выборка.

Чтобы сформулировать из нейронов сеть, необходимо соединить нейроны весами. Изначально, мы не знаем, какие веса соответствуют каждому соединению (если бы мы их знали, задача уже была бы решена). Выходит, данные веса необходимо подобрать, опираясь на данные из обучающей выборки. Задача обучения в нейронных сетях подразумевает как создание архитектуры расположения и связей нейронов, так и нахождение с последующей корректировкой весов. Для этого используется ошибка прямого распространения и связанный с ней метод обратного распространения ошибки (англ. backpropagation).
## Функционал ошибки
Прямое распространение – это вычисление ответа нейронной сети посредством последовательного вычисления значений каждого нейрона, на базе входных данных, с заранее известными весами. Конечный ответ нейронной сети используется в функции ошибки, для последующей корректировки весов нейронов, посредством минимизации. Рассмотрим наиболее распространенные функции ошибки:
\1) Cross-Entropy – энтропия

CE= -1Ni=1Nyi\*logyi=-(y\*logy+1-y\*log⁡(1-y)

\2) MSE (Mean Squared Error) – квадрат средней ошибки
MSE=1Ni=1N(yi-yi)2

\3) Root MSE (Mean Squared Error) – корень квадрата средней ошибки

RMSE=1Ni=1N(yi-yi)2

Где yi- ответ нейронной сети (значение выходного слоя); yi- значение метки, истинного предполагаемого значения предсказания;

Метод обратного распространения ошибки – это основной алгоритм обучения нейросетей, эквивалентный дифференцированию сложной функции – это метод распространения обратной ошибки. Принципиальная схема расчета обратного распространения ошибки на примере 1 абстрактного нейрона изображена на рисунке (Рисунок 4). При расчете производных используется следующее правило из математического анализа:

∂L∂x=∂L∂z∂z∂x

Важно отметить, что после каждого слоя следует функция активация, которая фигурирует в контексте модели, как нелинейное преобразование. Известно, линейная комбинация линейных комбинаций – это линейная комбинация, значит без функций активации вся нейронная сеть будет равносильна 1 нейрону.

w1w2w3x+ b3+b2+b1=w1w2w3x+w1w2b3+w1b2+b1≡wx+ b

Тогда линейная комбинация нелинейных комбинаций – нелинейная комбинация. Последовательность нелинейных преобразований способствует изучению моделью более глубоких закономерностей и извлечения признаков.

![](https://user-images.githubusercontent.com/77668803/174447707-909d0e8e-89a7-417f-ae0a-99c56d031714.png)
*Рисунок 4- расчет backprop*

Нейронная сеть шаг за шагом выстраивает новое признаковое представление исходных данных. Изначально модель работает с исходными признаками, а после первого слоя модель получает новое признаковое представление того объекта, который пришел на вход, затем после второго слоя у модели снова появляется новое признаковое представление изначального объекта и так далее. Для того чтобы признаковое представление не линейно менялись (не были линейной комбинацией исходных признаков) используются нелинейные функции активации.
## Функции активации
1) Сигмоидальная функция активации (sigmoid) - Рисунок 5
   σx= 11+ex

![](https://user-images.githubusercontent.com/77668803/174447719-d3b9edc1-29d0-4dd7-8f25-ac94fe13b2e3.png)
*Рисунок 5- sigmoid*

- переводит числа в промежуток [0, 1]
- исторически популярна, так как отлично интерпретируется как “пороговое значение активации” нейрона
- затухание градиентов из-за того, что “хвосты” плоскости
- вывод не нормированный, идет постоянный сдвиг значения
1) Гиперболический тангенс (tanh) - Рисунок 6
   tanhx= e2x-1e2x+1

![](https://user-images.githubusercontent.com/77668803/174447753-8220a8f2-1462-417a-9800-2202934cd4c7.png)

*Рисунок 6- tanh*

- переводит числа в промежуток [-1, 1] (вывод нормированный)
- в отличие от сигмоидальной функции значения центрированный
- проблема затухания градиентов все еще актуальна
1) Функция ReLu (Rectified Linear Unit) - Рисунок 7
   ReLux=max⁡(0, a)

![](https://user-images.githubusercontent.com/77668803/174447760-b036e137-c146-4cda-8f96-19c549ece6e6.jpeg)

*Рисунок 7- ReLu*

- решена проблема затухаещего градиента – справа градиент всегда равен единице
- эффективна с точки зрения вычислений
- однако, вывод не нормирован
- проблема с градиентов в левой части, когда x<0
1) Функция Leaky ReLu - Рисунок 8
   fx=max0.01x, x или fx=max⁡(αx,x)

![](https://user-images.githubusercontent.com/77668803/174447776-38b64d55-d58d-4133-9712-035fe054c548.png)

*Рисунок 8- Leaky ReLu*

- решена проблема затухания градиентов с обоих сторон
- эффективна с точки зрения вычислений
- имеет оптимизируемый параметр
# **Сверточные нейронные сети**
Задача по распознаванию кисти руки в реальном времени сводится к распознаванию кисти руки на каждом кадре из видео, получать ответы от модели кадр за кадром. Обработка изображений нейронными сетями более интерпретируемая задача, потому что изображение можно рассматривать, как матрицу пикселей, которые обладают определенном значением цвета (например, в палитре RGB). Однако концепция полносвязных нейронных сетей, разобранная ранее, имеет существенные недостатки:

1. Сложность вычислений, зависит напрямую от разрешения изображения. Входными значениями для изображения размера (n, m) будет вектор размера (n\*m\*3, 1), тройка появилась из соображений цветовой палитры RGB. При рассмотрении форматов высокого разрешения, количество вычислений для 1 слоя будет свыше 3 миллионов.
1. При использовании вектора из пикселей, обычная нейронная сеть будет рассматривать как набор неких значений, не выделяя характерные для изображения паттерны и свойства. Происходит потеря информации, получаемой из взаимного расположения пикселей.
## Свертки
Исходя из этих недостатков была сформулирована концепция сверточных нейронных сетей (англ. Convolutional neural networks). Сверточные нейронные сети используют ядера свертки (фильтры), чтобы произвести саму свертку. Фильтр – это квадратная матрица размера, которая сворачивает исходное изображение до меньшего размера, передвигаясь по нему слева направо сверху вниз на величину, которая называется stride. Операция свертки – это сумма поэлементног оперемноения матрицы и области, охватываемого этим ядром из исходного изображения (Рисунок 9)

![](https://user-images.githubusercontent.com/77668803/174447784-b7902cdc-c494-4f74-bfe9-00c03a3bfd65.png)

*Рисунок 9- операция свертки*

Полученная свертка называется картой активации. Фильтры “реагируют” на паттерны на изображении. Если паттерн присутствует на изображении, то карта активации после соответствующего фильтра будет содержать большие числа. Эта реакция по сути и решает проблему использования информации взаимного расположения пикселей на изображении. Разные фильтры реагируют на соответствующие паттерны, в конечном результате, если числа на карте активации большие – произошла активация. Именно поэтому результат свертки называется картой активации. Разные ядра способны различать разные паттерны, начиная от горизональных или вертикальных линий и заканчивая, например, чертами лица человека. Стоит отметить, что ядро является обучаемым параметром сети – это значит, что человеку не нужно самому формулировать фильтры распознающие определенные фильтры, нейронная сеть по мере углубления будет корректировать ядра самостоятельно, настраивая их на более сложные паттерны, характерные для конкретной задачи. После получения карт активаций, происходит их разворачиваение в векторы и последующая конкатенация, чтобы подать на вход полносвязной сети. Стоит отметить, что за каждым сверточным слоем используется функция активации, чтобы сделать преобразования нелинейными.
## Предобученные нейросети
Часто набор данных под какую-либо задачу содержит мало объектов. И если обучать сеть на этом нём с нуля, то сеть переобучится или наоборот, не сможет выявить закономерности. Например, машинный перевод с малораспространенных языков, таких так татарский. Тогда можно использовать знания, полученные другими сетями на похожих задачах (Рисунок 10). Набор весов и параметров экспортируется в файл конфигурации и может использоваться в других задачах, как с целью применения сразу, так и с целью дообучения на имеющихся данных.

![](https://user-images.githubusercontent.com/77668803/174447797-a3cf4af2-0671-41a9-a420-c5b7edb8beab.png)

*Рисунок 10- предобученные нейросети*
# **Фреймворк MediaPipe**
В проекте используется фреймворк MediaPipe с открытым кодом от компании Google. Данный модуль содержит в основе ансамбль из двух предобученных моделей, который распознает в кадре кисть человека и возвращает координаты 21 ключевой точки руки. Рассмотрим подробнее ансамбль и выводы модели.

![](https://user-images.githubusercontent.com/77668803/174447812-9c5a5ec3-b9e8-47a8-8435-232c8b43098c.png)

*Рисунок 11- ансамбль MediaPipe*
## Детектор ладони
Как было сказано ранее, ансамбль содержит 2 модели (Рисунок 11). Первая модель – это детектор ладони (BlazePalm), который принимает на вход полное изображение из видео и возвращает ориентированный bounding box (рамка). Преимущество данного заключается в том, что распознавание ладони или кулака, гораздо более простая и быстрая задача, чем распознавание всей руки с жестикулирующими пальцами. Архитектура BlazePalm изображена на рисунке (Рисунок 12), она относится к виду моделей single shot detector (SSD) и представляет собой последовательность из сверточных слоев, которые производят коллекцию ограничивающих рамок фиксированного размера и оценки наличия объекта в этих рамках. После сверток идет финальная оценка результатов и вывод итоговой рамки (Рисунок 13). Иначе говоря, данная модель дискретизирует выходное пространство ограничивающих рамок, а во время прогнозирования сопоставляет каждой рамке какой-то балл, показывающий уверенность модели в том, что какой-либо объект находится в рамках.  В итоге модель объединяет полученные прогнозы и возвращает координаты рамки той области, где средний балл остальных оценочных рамок был больше порогового значения. Чтобы обучать эту нейронную сеть, необходимо заранее выделить “области истинности” на изображении – области, которые действительно содержат объект.

![](https://user-images.githubusercontent.com/77668803/174447823-ff3729d2-7d86-4d9d-b728-85c51ebde514.png)

*Рисунок 12- архитектура single shot detector*

![](https://user-images.githubusercontent.com/77668803/174447831-33c647cf-7425-4768-90d7-e06b3e17affc.png)

*Рисунок 13- принципиальная структура BlazePalm*
## Модель распознавания точек руки
После выявления области, в которой находится ладонь, при помощи BlazePalm, решается задачи регрессии, по предсказанию местонахождения ключевых точек руки. Важно отметить, эта часть задачи происходит не со всем исходным изображением, а только с областью, в которой находится рука, найденная ранее. Эта модель также является CNN (Рисунок 14), однако обучается не целиком, а только последние её слои, которые выявляют особенные паттерны, а не общие (например, прямые вертикальные линии). Такой режим обучения называется feature extraction approach. 

![](https://user-images.githubusercontent.com/77668803/174447841-4189dcb6-0734-40c3-97b0-255627e14ba3.png)

*Рисунок 14- структура сети для выявления ключевых точек*

В результате модель возвращает 21 ключевую точку руки (Рисунок 15), достаточные для качественного распознавания жеста, класс руки (правая или левая), а также вероятность того, что на изображении присутствует рука. В ключевые точки входят все фаланги пальцев, а также основные точки ладони (например, основание ладони – точка 0).

![](https://user-images.githubusercontent.com/77668803/174447852-fb56ed39-085b-44ba-b300-7b6cde8abd36.png)

*Рисунок 15- 21 ключевая точка*

Вывод модели представлен в абсолютных координатах на входящем изображении, однако это не очень удобно, ведь рука может показывать тот или иной жест как в левом верхнем углу кадра, так и в нижнем правом. В данной курсовой работе имплементировано собственное решение задачи классификации жестов руки. В качестве исходных данных используются относительные координаты ключевых точек кисти руки, описанные ранее. Расчет производится относительно основания ладони – точки 0. Таким образом положение руки в кадре не влияет на точность предсказания.

Входные данные в модель классификации жестов – это относительные координаты, записанные в формате .csv ([приложение 1](#Приложение1)). В приложении есть 2 режима записи данных для обучения, которые активируются нажатием на определенные клавиши клавиатуры или нажатием на кнопки интерфейса. Затем необходимо нажать кнопку, которая отвечает за номер класса и координаты будут записаны в файл. Первый режим соответствует записи жеста руки, то есть знак из пальцев и ладони (например, Ок или пис), данный режим является наиболее простым в интерпретации и может найти самое больше применение. Другой режим позволяет записывать данные о траектории, которую показывает человек, указательным пальцем. Таким образом приложение поддерживает распознавание не только статических, но и динамических жестов кисти руки человека.
# **Классификаторы жестов и движений**
Как было написано ранее один объект, соответствующий жесту руки, описывается массивом из 21 координаты по обоим осям (всего 42) и меткой класса, которая соответствует нажатой в момент сбора данных кнопке (Приложение 2). Для еще в коде программы производится нормализация данных и перевод их в диапазон от 0 до 1.
## Нормализация данных
Рассмотрим пример некоторой выборки данных в двумерном пространстве с признаками по осям (Рисунок 16- нормализация данныхРисунок 16). Заметим, что изначальная выборка смещена относительно центра и имеет разброс, это может привести к уменьшению качества работы модели и как следствие точности. Это происходит, потому что разделяющаей плоскости будет сложно отделять классы из-за большого скопления объектов в одном направлении и небольшого в другом. Тогда следует отнормируем данные путем их ценрализации – графики посередине и справа. Разделим разделим значение данного признака у всех обьектов на максимум.

xi=xixmax , где xmax – максимальное значение данного признака по всей выборке. После этого преобразования провести точную разделяющую поверхность гораздно проще.

![](https://user-images.githubusercontent.com/77668803/174447867-a2592d10-aee6-477f-946a-b6f58b4965d2.jpeg)

*Рисунок 16- нормализация данных*

Нейронная сеть обучается с использованием определенных методов, которые позволяют улучшить результат. Рассмотрим методы, которые использовались в данной курсовой работе.
## Оптимизаторы
Для вычисления новых весов нейронов используют градиентный спуск со стандартной оптимизацией SGD (stochastic gradient descent – стохастический градиентный спуск). В SGD фигурирует лишь один изменяемый параметр – lr (learning rate – скорость обучения), который определяет размер шага при поиске минимума функции. Однако SGD имеет и недостатки, например, плохая реакция на шумные данные, а также опасность попасть в “ловушку” локального минимума и не найти глобальный.

SGD:  xt+1=xt-learning rate\*∇f(xi) 

Избежать “ловушки” локального минимума можно используя momentum (англ. импульс). Концепция momentum’а заключается в накоплении весов с предыдущих итераций и так называемого “движения по инерции”.

SGD with momentum: 

vt+1=ρvt+∇f(xt)

xt+1=xt-αvt+1

Где α – learning rate, v – параметр импульса, некая накопительная переменная. Однако есть возможность улучшить и SGD с momentum – это Nesterov momentum. Позволим нашей модели как бы “заглядывать в будущее”. Особенность метода заключается в том, что сначала происходит сдвиг по “инерции", а только потом расчет градиента.

` `SGD with Nesterov momentum: 

vt+1=ρvt+∇f(xt+ ρvt)

xt+1=xt-αvt+1

Для еще большей оптимизации работы модели добавляется задача создания адаптивного learning rate для каждого признака, который изменялся по мере итераций. Такой подход называется Adagrad: SGD with cache, которая характеризуется сохранением старых градиентов.

cachet+1= cachet +(∇f(xt))2

xt+1=xt-α∇fxtcachet+1+ε

Где cache – переменная для накапливания, что-то похожее на v в momentum, а ε – очень маленькое число, чтобы исключить случаи деления на 0.

Однако в случае Adagrad появляется проблема затухания градиента, когда знаменатель становится очень большой. Эту проблему решает RMSprop, концепция которого заключается в модификации Adagrad экспоненциальным сглаживанием.

cachet+1= βcachet +(1-β)(∇f(xt))2

xt+1=xt-α∇fxtcachet+1+ε

Где β – сглаживающий коэффициент <1.

Подведем итог, есть идея накапливать некий импульс и двигаться по “инерции” (momentum), а также нормировать каждую компоненту градиента на какое-то число (RMSprop). Тогда исходя из отсутствия противоречия, эти две идеи объединяют. Adam (adaptive learning rate optimization) – комбинация двух ранее представленных подходов.

vt+1=ρvt+(1-γ)∇f(xt+ ρvt)

cachet+1= βcachet +(1-β)(∇f(xt))2

xt+1=xt-αvt+1cachet+1+ε

## Переобучение
Для нейросетей существует проблема переобучения (overfitting), она характеризуется слишком большими весами для определенных нейронов сети и как следствие вклад этих нейронов в результат будет гораздо больше – это искажает результат. Эту проблему можно решать при помощи метода dropout, который заключается в случайном “выключении” нейронов (Рисунок 17). Выключение подрузамевает обнуление весов на 1 проход. Особенность данного подхода в том, что нейронная сеть будет делать предсказания опираясь на вывод из всех нейронов, а не только каких-то определенных, потому что они могут быть выключены. Таким образом остальные нейроны слоя будут корректировать свое значение, пытаясь заменить выключенный нейрон, что гарантирует защиту от переобучения.

![](https://user-images.githubusercontent.com/77668803/174447882-c3a9343b-ef3e-4c31-8629-8ec44c18199b.png)

*Рисунок 17- dropout*
## Предсказание вероятностей
Когда в задаче много классов, достаточно трудно воспринимать и анализировать результаты работы модели. Вводятся вероятности принадлежности объекта к классу, что позволяет получать больше информации о качестве работы модели. Рассмотрим функцию softmax(Рисунок 18), которая позволяет работать с большим количеством классов.

σ(z)i=ezij=1Kezj

Где K – количество классов на которые могут подразделяться объекты.
В конечном итоге для всех элементов выходного вектора значений применяется softmax. Эта функция отражает принадлежность элемента к каждому классу. В конечном итоге объект относится к тому классу, вероятность принадлежности к которому максимальна.

![](https://user-images.githubusercontent.com/77668803/174447902-8da52f72-3825-493c-b457-f41f28d40e8b.jpeg)

*Рисунок 18- softmax*
## Архитектура
Нейронная сеть, осуществляющая классификацию (Рисунок 19), имеет Adam в качестве оптимизатора, dropout для защиты от переобучения и упомянутую ранее функцию потерь Cross-entropy. На выходы сети представляют собой вектор вероятностей принадлежности к классам. Введем понятия, чтобы корректно описать процесс обучения:

- Партия (англ. batch) – характеризуется гиперпараметром batch size и отражает количество объектов, которые изучит модель, прежде чем обновить параметры. Если размер партии равен единице – это будет SGD, описанный ранее.
- Эпоха (англ. epoch) – гиперпараметр сети, который отражает, сколько раз модель обучится на исходном наборе данных. Если в одной эпохе используется 1 партия целиком – это будет GD.

` `При обучении, модель, используемая в работе, совершает 1000 эпох и имеет размер партии равный 128 (Приложение 3).

![](https://user-images.githubusercontent.com/77668803/174447909-2c45afe2-81ad-4624-99d0-8363e4014353.png)

*Рисунок 19- архитектура классификатора*
# **Реализация функционала приложения**
Приложение написано на языке программирования Python с использованием библиотеки Tkinter для реализации интерфейса и библиотеки OpenCV для обработки и вывода видео. Графический интерфейс (Рисунок 20) представляет собой окно, которое содержит рамку с видео, на котором отображается информация о количестве кадров и показываемом жесте. Остальная часть в той или иной мере дублирует и упрощает восприятие информации с основного видео. Это сделано для простоты использования, но не является обязательной частью, это значит, что видео можно размещать в любом интерфейсе дополнительно. Как было сказано ранее, приложение может распознавать 2 вида знаков, которые можно показать руками. Первый – статический жест, в то время как второй – динамический. Происходит анализ траектории, рисуемый по воздуху пользователем, который вытянул указательный палец. Модели, осуществляющие классификацию, импортируются из других файлов (Приложение 4) и способны оперативно выдавать прогноз, не замедляя работу приложения.

![](https://user-images.githubusercontent.com/77668803/174447917-ec2a02d0-4a2f-45ab-895c-3d2b7700ee54.png)

*Рисунок 20- графический интерфейс приложения*
# **Заключение**
В результате выполнения данной работы были получены следующие знания и практические умения:

1. Изучены принципы работы и обучения полносвязных нейронных сетей как с теоретической, так и с практической точки зрения.
1. Изучена концепция сверточных нейронных сетей, а также рассмотрена архитектура сложной сверточной сети для выполнения задачи определения ключевых точек руки.
1. Получены навыки работы с документацией на английском языке при подборе и анализе предобученных моделей.
1. Освоены навыки применения стороннего фреймворка с сопутствующим изучением докуменации и функций.
1. Изучены и применены на практике методы оптимизации нейронных сетей с целью повышения их качества работы.
1. Получены знания по работе с такими библиотеками как OpenCv, Tkinter, Keras
1. Приобретены навыки проектировки и разработки графического интерфейса.

Модели классификации показывают хорошее качество по различным метрикам для классификации, приложение работает стабильно и распознает жесты кисти руки клиента, позволяя сохранять эти данные для последующего дообучения.
# **Список использованной литературы**
1. Towards Accurate Multi-person Pose Estimation in the Wild 2017. URL: <https://arxiv.org/abs/1701.01779>
1. Using Deep Convolutional Networks for Gesture Recognition in American Sign Language 2017. URL: <https://arxiv.org/abs/1710.06836>
1. On-Device, Real-Time Hand Tracking with MediaPipe – статья Google AI Blog 2019. URL: <https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html>
1. SSD: Single Shot MultiBox Detector 2016. URL: [https://arxiv.org/abs/1512.02325]()
1. MediaPipe Hands: On-device Real-time Hand Tracking 2020. URL: <https://arxiv.org/abs/2006.10214>
1. Документация фреймворка MediaPipe Hands URL: <https://google.github.io/mediapipe/solutions/hands> (Дата обращения 17.04.2022)
1. OpenCV: Computer Vision Projects with Python Joseph Howse, Prateek Joshi, Michael Beyeler 2016
1. OpenCV with Python Blueprints By Dr. Menua Gevorgyan, Arsen Mamikonyan , Michael Beyeler 2020
1. Python GUI Programming with Tkinter. Develop responsive and powerful GUI applications with Tkinter Alan D. Moore 2018
1. ` `An Introduction to Convolutional Neural Networks 2015 URL: https://arxiv.org/abs/1511.08458
# **Приложения**
Приложение 1. Функция, реализующая протокол записи относительных координат ключевых точек в csv-файл. Код приведен на языке программирования Python в редакторе кода Pycharm.

![](https://user-images.githubusercontent.com/77668803/174447929-caaba36e-8c70-46e5-b8c4-42a7cc5932ff.png)

Приложение 2. Импорт данных в csv формате в Jupiter notebook, для последующего обучения. Код на языке программирования Python.

![](https://user-images.githubusercontent.com/77668803/174447935-a0c891a9-94dd-48cb-aead-6c5827b5903a.png)

Приложение 3. Обучение модели для классификации жестов руки в Jupiter notebook. Код приведен на языке программирования Python.

![](https://user-images.githubusercontent.com/77668803/174447943-c5e9a98e-1bc6-4ea1-b755-7a04a09da6b2.png)

Приложение 4. Класс, использующий обученную ранее модель и позволяющий делать прогноз по одному объекту. Код приведен на языке программирования Python.

![](https://user-images.githubusercontent.com/77668803/174447950-afcac9d2-a550-411f-b589-ccb1ad986904.png)
